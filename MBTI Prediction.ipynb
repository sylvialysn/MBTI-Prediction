{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...\n",
       "...    ...                                                ...\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...\n",
       "8671  ENFP  'So...if this thread already exists someplace ...\n",
       "8672  INTP  'So many questions when i do these things.  I ...\n",
       "8673  INFP  'I am very conflicted right now when it comes ...\n",
       "8674  INFP  'It has been too long since I have been on per...\n",
       "\n",
       "[8675 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a column for 'I-E'which is Introversion/Extraversion\n",
    "data['I-E']= data['type'].apply(lambda x: \"I\" if x[0]=='I' else 'E' )\n",
    "\n",
    "# Make a column for 'N-S'which is Intuition/Sensing\n",
    "data['N-S']= data['type'].apply(lambda x: \"N\" if x[1]=='N' else 'S' )\n",
    "\n",
    "# Make a column for 'T-F'which is Thinking/Feeling\n",
    "data['T-F']= data['type'].apply(lambda x: \"T\" if x[2]=='T' else 'F' )\n",
    "\n",
    "# Make a column for 'J-P'which is Judging/Perceiving\n",
    "data['J-P']= data['type'].apply(lambda x: \"J\" if x[3]=='J' else 'P' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>I-E</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8670</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'https://www.youtube.com/watch?v=t8edHB_h908||...</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8671</th>\n",
       "      <td>ENFP</td>\n",
       "      <td>'So...if this thread already exists someplace ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8672</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'So many questions when i do these things.  I ...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8673</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I am very conflicted right now when it comes ...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8674</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'It has been too long since I have been on per...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8675 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts I-E N-S T-F J-P\n",
       "0     INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   I   N   F   J\n",
       "1     ENTP  'I'm finding the lack of me in these posts ver...   E   N   T   P\n",
       "2     INTP  'Good one  _____   https://www.youtube.com/wat...   I   N   T   P\n",
       "3     INTJ  'Dear INTP,   I enjoyed our conversation the o...   I   N   T   J\n",
       "4     ENTJ  'You're fired.|||That's another silly misconce...   E   N   T   J\n",
       "...    ...                                                ...  ..  ..  ..  ..\n",
       "8670  ISFP  'https://www.youtube.com/watch?v=t8edHB_h908||...   I   S   F   P\n",
       "8671  ENFP  'So...if this thread already exists someplace ...   E   N   F   P\n",
       "8672  INTP  'So many questions when i do these things.  I ...   I   N   T   P\n",
       "8673  INFP  'I am very conflicted right now when it comes ...   I   N   F   P\n",
       "8674  INFP  'It has been too long since I have been on per...   I   N   F   P\n",
       "\n",
       "[8675 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sylvi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sylvi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')  # Download the WordNet dataset if you haven't already\n",
    "\n",
    "\n",
    "# Cast Folding\n",
    "def to_lower(text):     \n",
    "    return text.lower()\n",
    "\n",
    "def remove_urls(text):\n",
    "    # Define a regular expression pattern to match URLs starting with 'http' or 'https'\n",
    "    url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "\n",
    "    # Use the re.sub() function to replace all URL matches with an empty string\n",
    "    text = re.sub(url_pattern, '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "# Get the list of English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stopwords(text):\n",
    "    # Remove stopwords from the list of words\n",
    "    text = ' '.join(c for c in text.split() if c not in stop_words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def remove_mbti_labels(text):\n",
    "    # Define a list of MBTI labels\n",
    "    mbti_labels = ['infj', 'infp', 'intj', 'intp', 'isfj', 'isfp', 'istj', 'istp', 'enfj', 'enfp', 'entj', 'entp', 'esfj', 'esfp', 'estj', 'estp'] \n",
    "    \n",
    "    # Remove MBTI labels from the list of words\n",
    "    text = ' '.join(c for c in text.split() if c not in mbti_labels)\n",
    "\n",
    "    return text\n",
    "\n",
    "def remove_punct(text):     # Remove Punctuation, artinya dalam setiap baris dicari setiap huruf. if dia bukan punctuation maka akan kembali dijoin. jika iya punctuation akan hilang \n",
    "    return ''.join(c for c in text if c not in string.punctuation)\n",
    "    \n",
    "def remove_number(text):        # Remove Number\n",
    "    return ''.join(c for c in text if not c.isdigit())\n",
    "\n",
    "def to_strip(text):\n",
    "    return ' '.join(text.split()) # Remove whitespace \n",
    "\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = nltk.word_tokenize(text)\n",
    "    # Lemmatize each word and join them back into a sentence\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Combine all function \n",
    "def prepro(text): \n",
    "    pre = to_lower(str(text))\n",
    "    pre = remove_urls(pre)\n",
    "    pre = remove_punct(pre)\n",
    "    pre = remove_number(pre)\n",
    "    pre = to_strip(pre)\n",
    "    pre = stopwords(pre)\n",
    "    pre = remove_mbti_labels(pre)\n",
    "    pre = lemmatize(pre)\n",
    "    \n",
    "    return pre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean']=data['posts'].apply(prepro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       moment sportscenter top ten play prankswhat li...\n",
       "1       im finding lack post alarmingsex boring positi...\n",
       "2       good one course say know thats blessing cursed...\n",
       "3       dear enjoyed conversation day esoteric gabbing...\n",
       "4       youre firedthats another silly misconception a...\n",
       "                              ...                        \n",
       "8670    always think cat fi doms reason website become...\n",
       "8671    soif thread already exists someplace else heck...\n",
       "8672    many question thing would take purple pill pic...\n",
       "8673    conflicted right come wanting child honestly m...\n",
       "8674    long since personalitycafe although doesnt see...\n",
       "Name: clean, Length: 8675, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "X = data[['clean']]\n",
    "y_I_E = data['I-E']\n",
    "y_N_S = data['N-S']\n",
    "y_T_F = data['T-F']\n",
    "y_J_P = data['J-P']\n",
    "\n",
    "# Split the data for 'I-E' while ensuring stratification\n",
    "X_train_I_E, X_test_I_E, y_train_I_E, y_test_I_E = train_test_split(X, y_I_E, test_size=0.2, random_state=42, stratify=y_I_E)\n",
    "\n",
    "# Split the data for 'N-S' while ensuring stratification\n",
    "X_train_N_S, X_test_N_S, y_train_N_S, y_test_N_S = train_test_split(X, y_N_S, test_size=0.2, random_state=42, stratify=y_N_S)\n",
    "\n",
    "# Split the data for 'T-F' while ensuring stratification\n",
    "X_train_T_F, X_test_T_F, y_train_T_F, y_test_T_F = train_test_split(X, y_T_F, test_size=0.2, random_state=42, stratify=y_T_F)\n",
    "\n",
    "# Split the data for 'J-P' while ensuring stratification\n",
    "X_train_J_P, X_test_J_P, y_train_J_P, y_test_J_P = train_test_split(X, y_J_P, test_size=0.2, random_state=42, stratify=y_J_P)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I-E (Vectorizer and modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I-E\n",
       "I    76.956772\n",
       "E    23.043228\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['I-E'].value_counts()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create a TfidfVectorizer for 'I-E' dimension\n",
    "vectorizer_I_E = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train_vec_I_E = vectorizer_I_E.fit_transform(X_train_I_E['clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7353647062282695\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           E       0.58      0.61      0.60       400\n",
      "           I       0.88      0.87      0.87      1335\n",
      "\n",
      "    accuracy                           0.81      1735\n",
      "   macro avg       0.73      0.74      0.74      1735\n",
      "weighted avg       0.81      0.81      0.81      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=['I', 'E'], y=y_train_I_E)\n",
    "\n",
    "model_IELg = Pipeline([('TFID', vectorizer_I_E),\n",
    "                       ('clf', LogisticRegression(class_weight={'I':class_weights[0],'E':class_weights[1]}))\n",
    "                       ])\n",
    "\n",
    "model_IELg.fit(X_train_I_E['clean'],y_train_I_E)\n",
    "predIELg = model_IELg.predict(X_test_I_E['clean'])\n",
    "print(f1_score(y_test_I_E,predIELg, average = 'macro'))\n",
    "print(classification_report(y_test_I_E,predIELg))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-S (Vectorizer and modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N-S\n",
       "N    86.201729\n",
       "S    13.798271\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['N-S'].value_counts()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer for 'N-S' dimension\n",
    "vectorizer_N_S = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train_vec_N_S = vectorizer_N_S.fit_transform(X_train_N_S['clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7050213449306504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           N       0.92      0.92      0.92      1496\n",
      "           S       0.50      0.48      0.49       239\n",
      "\n",
      "    accuracy                           0.86      1735\n",
      "   macro avg       0.71      0.70      0.71      1735\n",
      "weighted avg       0.86      0.86      0.86      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=['N', 'S'], y=y_train_N_S)\n",
    "\n",
    "model_NSLg = Pipeline([('TFID', vectorizer_N_S),\n",
    "                       ('clf', LogisticRegression(class_weight={'N':class_weights[0],'S':class_weights[1]}))\n",
    "                       ])\n",
    "\n",
    "model_NSLg.fit(X_train_N_S['clean'],y_train_N_S)\n",
    "predNSLg = model_NSLg.predict(X_test_N_S['clean'])\n",
    "print(f1_score(y_test_N_S,predNSLg, average = 'macro'))\n",
    "print(classification_report(y_test_N_S,predNSLg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-F (Vectorizer and modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T-F\n",
       "F    54.10951\n",
       "T    45.89049\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['T-F'].value_counts()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer for 'T-F' dimension\n",
    "vectorizer_T_F = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train_vec_T_F = vectorizer_T_F.fit_transform(X_train_T_F['clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8187001079342886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           F       0.84      0.82      0.83       939\n",
      "           T       0.80      0.82      0.81       796\n",
      "\n",
      "    accuracy                           0.82      1735\n",
      "   macro avg       0.82      0.82      0.82      1735\n",
      "weighted avg       0.82      0.82      0.82      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=['T', 'F'], y=y_train_T_F)\n",
    "\n",
    "model_TFLg = Pipeline([('TFID', vectorizer_T_F),\n",
    "                       ('clf', LogisticRegression(class_weight={'T':class_weights[0],'F':class_weights[1]}))\n",
    "                       ])\n",
    "\n",
    "model_TFLg.fit(X_train_T_F['clean'],y_train_T_F)\n",
    "predTFLg = model_TFLg.predict(X_test_T_F['clean'])\n",
    "print(f1_score(y_test_T_F,predTFLg, average = 'macro'))\n",
    "print(classification_report(y_test_T_F,predTFLg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## J-P (Vectorizer and modelling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "J-P\n",
       "P    60.414986\n",
       "J    39.585014\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['J-P'].value_counts()/len(data)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a TfidfVectorizer for 'J-P' dimension\n",
    "vectorizer_J_P = TfidfVectorizer(ngram_range=(1,1))\n",
    "X_train_vec_J_P = vectorizer_J_P.fit_transform(X_train_J_P['clean'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7169897103573888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           J       0.66      0.66      0.66       687\n",
      "           P       0.78      0.77      0.78      1048\n",
      "\n",
      "    accuracy                           0.73      1735\n",
      "   macro avg       0.72      0.72      0.72      1735\n",
      "weighted avg       0.73      0.73      0.73      1735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=['J', 'P'], y=y_train_J_P)\n",
    "\n",
    "model_JPLg = Pipeline([('TFID', vectorizer_J_P),\n",
    "                       ('clf', LogisticRegression(class_weight={'J':class_weights[0],'P':class_weights[1]}))\n",
    "                       ])\n",
    "\n",
    "model_JPLg.fit(X_train_J_P['clean'],y_train_J_P)\n",
    "predJPLg = model_JPLg.predict(X_test_J_P['clean'])\n",
    "print(f1_score(y_test_J_P,predJPLg, average = 'macro'))\n",
    "print(classification_report(y_test_J_P,predJPLg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MBTI Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted MBTI Type: ['INFP']\n"
     ]
    }
   ],
   "source": [
    "new_post_text = input()\n",
    "post = [prepro(new_post_text)]  # Data preprocessing steps\n",
    "\n",
    "\n",
    "# Make predictions for each dimension (I-E, N-S, T-F, J-P) separately\n",
    "prediction_I_E = model_IELg.predict(post)\n",
    "prediction_N_S = model_NSLg.predict(post)\n",
    "prediction_T_F = model_TFLg.predict(post)\n",
    "prediction_J_P = model_JPLg.predict(post)\n",
    "\n",
    "# Combine predictions into the final MBTI type\n",
    "final_mbti_type = [prediction_I_E[0]+ prediction_N_S[0]+ prediction_T_F[0]+ prediction_J_P[0]]\n",
    "\n",
    "# Print the predicted MBTI type\n",
    "print(f\"Predicted MBTI Type: {final_mbti_type}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
